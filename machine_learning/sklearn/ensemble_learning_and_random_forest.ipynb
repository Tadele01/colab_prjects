{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these examples are taken from hands on machine learning book chapter 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensemble Learning and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#majority vote  classifier is called a hard voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('rc', rnd_clf), ('sc', svm_clf)],\n",
    "                             voting = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = iris.data\n",
    "iris_target = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, iris_target, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4.6, 3.6, 1. , 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.1, 3.5, 1.4, 0.2],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [5.9, 3. , 5.1, 1.8],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [7.1, 3. , 5.9, 2.1]]),\n",
       " array([0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 1, 2, 1, 2,\n",
       "        1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 2, 0, 2, 2,\n",
       "        1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 2, 1, 2, 2, 1,\n",
       "        0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 0, 2, 1, 2,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 1, 2, 2, 1, 2,\n",
       "        1, 1, 2, 2, 0, 1, 2, 0, 1, 2]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)), ('rc', RandomFo...bf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False))],\n",
       "         flatten_transform=None, n_jobs=None, voting='hard', weights=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 1.0\n",
      "RandomForestClassifier 1.0\n",
      "SVC 1.0\n",
      "VotingClassifier 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting_clf = VotingClassifier(estimators = [('lr', log_clf), ('rc', rnd_clf), ('sc', svm_clf)],\n",
    "                                  voting = 'soft')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "soft_voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 1.0\n",
      "RandomForestClassifier 1.0\n",
      "SVC 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tade/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for clf in(log_clf, rnd_clf, svm_clf, soft_voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging and Pasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators = 500, \n",
    "    max_samples = 100, bootstrap=True, n_jobs = -1\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to do pasting change the bootstrap hyperparameter to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find about out-of-bag evaluation we can set oob_score = True\n",
    "\n",
    "bag_oob_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators = 500, \n",
    "    max_samples = 100, n_jobs = -1, oob_score = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.9416666666666667)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_oob_clf.fit(X_train, y_train)\n",
    "y_pred = bag_oob_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc, bag_oob_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.06074766, 0.93925234],\n",
       "       [0.        , 0.99543379, 0.00456621],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.0376569 , 0.9623431 ],\n",
       "       [0.        , 0.95111111, 0.04888889],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.69585253, 0.30414747],\n",
       "       [0.        , 0.0044843 , 0.9955157 ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.99561404, 0.00438596],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.89855072, 0.10144928],\n",
       "       [0.        , 0.09049774, 0.90950226],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.04285714, 0.95714286],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.4028436 , 0.5971564 ],\n",
       "       [0.        , 0.04245283, 0.95754717],\n",
       "       [0.        , 0.92626728, 0.07373272],\n",
       "       [0.        , 0.99537037, 0.00462963],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.99473684, 0.00526316],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.9587156 , 0.0412844 ],\n",
       "       [0.        , 0.01408451, 0.98591549],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.00966184, 0.99033816],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.02857143, 0.97142857],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.03196347, 0.96803653],\n",
       "       [0.        , 0.99512195, 0.00487805],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.11688312, 0.88311688],\n",
       "       [0.        , 0.36585366, 0.63414634],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.86086957, 0.13913043],\n",
       "       [0.        , 0.01333333, 0.98666667],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.61674009, 0.38325991],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.21463415, 0.78536585],\n",
       "       [0.        , 0.99553571, 0.00446429],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.00473934, 0.99526066],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.99514563, 0.00485437],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.0044843 , 0.9955157 ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.76987448, 0.23012552],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.5       , 0.5       ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.73488372, 0.26511628],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.00487805, 0.99512195],\n",
       "       [0.        , 0.99568966, 0.00431034],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.12719298, 0.87280702],\n",
       "       [0.        , 0.07083333, 0.92916667],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.82949309, 0.17050691],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oob_function for each training examples\n",
    "bag_oob_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random patches and Random Subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The BaggingClassifier class supports sampling the features as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Keeping all training instances\\n(i.e., bootstrap=False and max_samples=1.0 ) but sampling features (i.e., bootstrap_features=True\\nand/or max_features smaller than 1.0) is called the Random Subspaces method.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is controlled by two hyperparameters: max_features and bootstrap_features .\n",
    "#Thus, each predictor will be trained on a random subset of the input features.\n",
    "#Sampling both training instances and features is called the Random Patches method.\n",
    "'''Keeping all training instances\n",
    "(i.e., bootstrap=False and max_samples=1.0 ) but sampling features (i.e., bootstrap_features=True\n",
    "and/or max_features smaller than 1.0) is called the Random Subspaces method.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_jobs=-1, n_estimators=500, max_leaf_nodes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred = rnd_clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.08794361522274312\n",
      "sepal width (cm) 0.03166100806676185\n",
      "petal length (cm) 0.43888388906282444\n",
      "petal width (cm) 0.441511487647671\n"
     ]
    }
   ],
   "source": [
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boosting refers to any ensemble method that can combine several weak learners into a strong learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weak learner means slightly better than a random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
